## create placeholder vector for
x <- rep(NA, n)
num.samples <- 0
for(i in 1:n){
ntrys <- 0
accept <- 0
while(accept==0) {
ntrys <- ntrys + 1
## step 1: sample from Y
y <- runif(1)
## step 2: draw U~unif(0,1)
u <- runif(1)
## step 3: accept / reject
h <- y^(a-1)*(1-y)^(b-1)
g <- 1
if(u<h / (K*g)){
accept <- 1
x[i] <- y
num.samples <- num.samples+ntrys
}
}
}
## return list with x=samples, and print total number of samples needed
cat("Total samples needed: ",num.samples,"\n")
return(x)
}
hist(betasamp(10000, a=2, b=5, K=10))
rtnorm <- function(n, mu, sigma, a, b){
## n = number of samples
## mu= mean
## sigma = standard deviation
## a = lower bound
## b = upper bound
x <- rep(NA, n)
for(i in 1:n) {
cat(i," ")
accept <- 0
while(accept==0) {
## step 1: draw y ~ N(mu,sigma^2)
y <- rnorm(1, mu, sigma)
## step 2: accept if y is in right region
if(y>a & y<b) {
x[i] <- y
accept <- 1
}
}
}
cat("\n")
return(x)
}
x <- rtnorm(10000, mu=3, sigma=1, a=0, b=4)
hist(x, breaks=20)
rexp
?rexp
rtexp <- function(n, lambda, a){
## n = number of samples
## mu= mean
## sigma = standard deviation
## a = lower bound
## b = upper bound
x <- rep(NA, n)
for(i in 1:n) {
cat(i," ")
accept <- 0
while(accept==0) {
## step 1: draw y ~ N(mu,sigma^2)
y <- rexp(1, rate = lambda)
## step 2: accept if y is in right region
if(y>a) {
x[i] <- y
accept <- 1
}
}
}
cat("\n")
return(x)
}
x <- rtexp(10000, lambda = 1, a=4.5)
hist(x, breaks=20)
hist(x, breaks=50)
hist(x, breaks=40)
hist(x, breaks=30)
hist(x, breaks=30)
hist(x, breaks=20)
hist(x, breaks=25)
hist(x, breaks=30)
hist(rexp(10000,1), breaks=30)
x <- rtexp(10000, lambda = 1, a=4.5)
hist(x, breaks=20)
samples <- rep(NA, draws)
draws = 10000
draws = 10000
lambda = 1
alpha = 4.5
samples <- rep(NA, draws)
samples <- rep(NA, draws)
i = 1
accept <- 0
accept <- 0
accept == 0
y <- rexp(1, rate = lambda)
y > alpha
accept <- 0
while (accept == 0) {
print("Try!")
y <- rexp(1, rate = lambda)
## step 2: accept if y is in right region
if(y > alpha) {
x[i] <- y
accept <- 1
}
}
rexp(1, rate = lambda)
rexp(1, rate = lambda)
rexp(1, rate = lambda)
rexp(1, rate = lambda)
rexp(1, rate = lambda)
rexp(1, rate = lambda)
rexp(1, rate = lambda)
rexp(1, rate = lambda)
rexp(1, rate = lambda)
rexp(1, rate = lambda)
rexp(1, rate = lambda)
rexp(1, rate = lambda)
accept <- 0
while (accept == 0) {
y <- rexp(1, rate = lambda)
cat("y value:",y,"\n")
## step 2: accept if y is in right region
if(y > alpha) {
cat("Found one!")
samples[i] <- y
accept <- 1
}
}
library(GERGM)
load("~/Dropbox/GERGM_Group/Manuscripts/Social_Networks_MH_GERGM/Supplemental_Material/Numerical_Scripts/RandR_Analysis/Output/Migration_Gibbs_Long_GERGM_Object.Rdata")
Estimate_Plot(GERGM_Object)
?Estimate_Plot
Estimate_Plot(GERGM_Object, coefficients_to_plot = "structural")
load("~/Dropbox/GERGM_Group/Manuscripts/Social_Networks_MH_GERGM/Supplemental_Material/Numerical_Scripts/RandR_Analysis/Output/Migration_MH_Fit_Separate.RData")
Estimate_Plot(GERGM_Object, coefficients_to_plot = "structural")
Rcpp::sourceCpp('Desktop/rdirichlet_cpp.cpp')
Rcpp::sourceCpp('Desktop/rdirichlet_cpp.cpp')
Rcpp::sourceCpp('Desktop/parallel_testing.cpp')
test <- vector_parallel(1:100000,100)
Rcpp::sourceCpp('Desktop/parallel_testing.cpp')
test <- vector_parallel(1:100000,100)
Rcpp::sourceCpp('Desktop/parallel_testing.cpp')
test <- vector_parallel(1:100000,100)
rm(list=ls())
set.seed(1234)
require(quanteda)
mycorp <- corpus(inaugTexts)
corp <- texts(mycorp)[1:50]#keep it simple
#1. do p aggressive reduction, but have k=2
quantdfm <- dfm(corp, tolower=T, removeNumbers=T, removePunct=T, stem=T,
ignoredFreatures=stopwords())
require(topicmodels)
LDAfit5_1 <- LDA(convert(quantdfm, to = "topicmodels"), k = 2)
dist1 <- dist(LDAfit5_1@gamma)
?stopwords
2^10
4^10
library("latentnet")
library("foreach")
library("iterators")
library("network")
install.packages("BatchExperiments")
install.packages("clusterGeneration")
library("clusterGeneration")
library("BatchExperiments")
library("BatchExperiments")
library("latentnet")
library("foreach")
library("clusterGeneration")
library("iterators")
create_network <- function(y, name = "eweight") {
library("network")
net <- network(y, directed = FALSE)
el <- as.matrix(net, "edgelist")
w <- y[el]
set.edge.attribute(net, name, w)
net
}
rmvnorm_d <- function(sigma, d) {
library("mvtnorm")
var_d <- var(d)
mu_d <- mean(d)
n_var <- ncol(sigma)
d_inv <- solve(as.matrix(var_d))
sigma_x <- sigma[1:(n_var - 1), 1:(n_var - 1)] - sigma[1:(n_var - 1), n_var] %*%
d_inv %*% sigma[n_var, 1:(n_var - 1)]
mu_x <- sapply(d, function(z) sigma[1:(n_var - 1), n_var] %*% d_inv %*% z - mu_d)
if (!is.matrix(mu_x))
as.matrix(sapply(mu_x, rnorm, n = 1, sd = sqrt(sigma_x)))
else
t(apply(mu_x, 2, function(mu) rmvnorm(1, mu, sigma_x)))
}
ms_error <- function(x, y, each_column = FALSE) {
if (each_column)
sapply((x - y)^2, mean)
else
mean((x - y)^2)
}
unstack_vector <- function(x, n) {
idx <- t(combn(1:n, 2))
mat <- diag(n)
mat[idx] <- x
mat[idx[, c(2, 1)]] <- x
stopifnot(isSymmetric(mat))
mat
}
diagnostic <- function(fit) {
stopifnot(any(class(fit) %in% "glm"))
SVD <- svd(scale(solve(vcov(fit)), center = FALSE))
max_d <- max(SVD$d)
CI <- sapply(SVD$d, function(x) max_d / x)
phi <- t((SVD$v %*% diag(1 / SVD$d))^2)
pi <- prop.table(phi, 2)
out <- data.frame(CI, pi)
colnames(out) <- c("ci", names(coef(fit)))
round(out, 3)
}
create_data <- function(static, family, eta, nodes, beta, latent_space) {
library("clusterGeneration")
C <- abs(cov2cor(genPositiveDefMat(static$p, "c-vine", eta = eta)$Sigma))
d <- as.matrix(dist(replicate(static$p, rnorm(nodes, 0, static$sigma))))
d <- d[lower.tri(d)]
d <- d / (sd(d) / sqrt(diag(C)[nrow(C)]))
X <- rmvnorm_d(C, d)
X <- (X - colMeans(X)) / apply(X, 2, sd)
lp <- beta * X + latent_space * d
y_stack <- switch(family,
gaussian = rnorm(length(lp), lp, static$sigma),
binomial = rbinom(length(lp), 1, 1 / (1 + exp(-(lp)))),
poisson = rpois(length(lp), exp(lp)))
y <- unstack_vector(y_stack, nodes)
X_stack <- data.frame(X)
X <- unstack_vector(X, nodes)
y_stack_new <- switch(family,
gaussian = rnorm(length(lp), lp, static$sigma),
binomial = rbinom(length(lp), 1, 1 / (1 + exp(-(lp)))),
poisson = rpois(length(lp), exp(lp)))
y_new <- unstack_vector(y_stack_new, nodes)
ret <- list(
p = if (family == "binomial") plogis(lp) else NULL,
d = d,
y = y,
y_stack = y_stack,
X = X,
X_stack = X_stack,
y_new = y_new,
y_stack_new = y_stack_new,
family = family,
nodes = nodes,
beta = beta,
latent_space = latent_space
)
ret
}
lsm.wrapper <- function(static, dynamic, ...) {
library("latentnet")
library("coda")
dots <- list(...)
net <- create_network(dynamic$y)
.GlobalEnv$X <- dynamic$X ## fuck you latentet
lf <- c("gaussian" = "Gaussian", "binomial" = "Bernoulli", "poisson" = "Poisson")
if (dots$scale) {
glm_fit <- glm(y ~ X, dynamic$family, data.frame(dynamic$X_stack, "y" = dynamic$y_stack))
prior_variance <- (abs(coef(glm_fit)[2]) * var(dynamic$X_stack)) / (2 - 4 / pi)
prior_variance <- unname(as.numeric(prior_variance))
prior <- ergmm.prior("Z.var" = prior_variance)
} else {
prior <- ergmm.prior(...)
}
fam.par <- list("prior.var" = static$sigma, "prior.var.df" = dynamic$nodes)
if (dynamic$family != "gaussian") fam.par <- NULL
flag <- TRUE
iter <- 1
while (flag) {
fit <- ergmm(net ~ edgecov(X) + euclidean(d = 1),
"eweight", unname(lf[names(lf) %in% dynamic$family]),
fam.par = fam.par, prior = prior,
tofit = c("mcmc", "pmode"), seed = static$seed,
control = static$control)
## assess convergence, re-run if necessary
geweke <- geweke.diag(as.mcmc(fit)[[1]])$z
if (abs(unname(geweke[["lpY"]])) < 1 | iter == static$maxit) {
flag <- FALSE
} else {
iter <- iter + 1
static$control$sample.size <- static$control$sample.size * 2
}
flag <- FALSE
}
pred <- predict(fit, newdata = create_network(dynamic$y_new, dynamic$X), type = "pmode")
list(
"pred" = pred,
"estimate" = fit$mcmc.pmode$beta[2],
"interval" = HPDinterval(as.mcmc(fit$sample$beta[, 2])),
"loss" = ms_error(pred, dynamic$y_new),
"convergence" = geweke,
"data" = dynamic,
"fit" = fit
)
}
glm.wrapper <- function(static, dynamic, ...) {
fit <- glm(y ~ X, dynamic$family, data.frame(dynamic$X_stack, "y" = dynamic$y_stack))
pred <- predict(fit, newdata = dynamic$X_stack, se.fit = TRUE, type = "response")
list(
"pred" = pred,
"estimate" = unname(coef(fit)[2]),
"adjustment" = sqrt(3.29 + var(dynamic$d)) / sqrt(3.29),
"interval" = confint(fit, colnames(dynamic$X_stack)),
"loss" = ms_error(pred$fit, dynamic$y_stack_new),
"data" = dynamic,
"fit" = fit
)
}
truth.wrapper <- function(static, dynamic, ...) {
fit <- glm(y ~ X + d, dynamic$family, data.frame(dynamic$X_stack, "y" = dynamic$y_stack, "d" = dynamic$d))
pred <- predict(fit, newdata = data.frame(dynamic$X_stack, "d" = dynamic$d), se.fit = TRUE, type = "response")
list(
"pred" = pred,
"estimate" = unname(coef(fit)[2]),
"adjustment" = sqrt(3.29 + var(dynamic$d)) / sqrt(3.29),
"interval" = confint(fit, colnames(dynamic$X_stack)),
"loss" = ms_error(pred$fit, dynamic$y_stack_new),
"data" = dynamic,
"fit" = fit
)
}
reg <- makeExperimentRegistry("lsm", "reg")
addProblem(reg, "test", dynamic = create_data, seed = 1234, overwrite = TRUE,
static = list(p = 2, sigma = 1, seed = 1234, maxit = 2,
control = ergmm.control(sample.size = 10000, burnin = 10000, interval = 100)))
problem.pars <- list(
"eta" = c(.1, 1, 100, 1000000),
"family" = c("gaussian", "binomial", "poisson"),
"nodes" = c(25, 50, 100),
"beta" = c(1, 0),
"latent_space" = c(-1, 0)
)
problem.design <- makeDesign("test", exhaustive = problem.pars)
4*3*3*2*2
glm.pars <- list()
truth.pars <- list()
lsm.design <- makeDesign("lsm", exhaustive = lsm.pars)
glm.design <- makeDesign("glm", exhaustive = glm.pars)
truth.design <- makeDesign("truth", exhaustive = truth.pars)
addAlgorithm(reg, "lsm", lsm.wrapper, overwrite = TRUE)
addAlgorithm(reg, "glm", glm.wrapper, overwrite = TRUE)
addAlgorithm(reg, "truth", truth.wrapper, overwrite = TRUE)
addExperiments(reg, problem.design, list("lsm" = lsm.design, "glm" = glm.design, "truth" = truth.design),
repls = 500, skip.defined = TRUE)
lsm.pars <- list("scale" = c(TRUE, FALSE),
"beta.var" = c(1, 10))
glm.pars <- list()
truth.pars <- list()
lsm.design <- makeDesign("lsm", exhaustive = lsm.pars)
glm.design <- makeDesign("glm", exhaustive = glm.pars)
truth.design <- makeDesign("truth", exhaustive = truth.pars)
addAlgorithm(reg, "lsm", lsm.wrapper, overwrite = TRUE)
addAlgorithm(reg, "glm", glm.wrapper, overwrite = TRUE)
addAlgorithm(reg, "truth", truth.wrapper, overwrite = TRUE)
addExperiments(reg, problem.design, list("lsm" = lsm.design, "glm" = glm.design, "truth" = truth.design),
repls = 500, skip.defined = TRUE)
load("~/Dropbox/Phrases/Data/Unigram_LDA_Results_No_Stopwords.RData")
unigram_results$topic_top_words
unigram_results$topic_top_phrases
Rcpp::sourceCpp('Dropbox/GERGM_Group/GERGM_Statistic_Multicollinearity/Scripts/06_Dirichlet_Draw.cpp')
alpha <- 10
draws <- 4
dimen <- 10
alpha_m <- rep(alpha/dimen, dimen)
x <- rdirichlet_cpp(draws,alpha_m)
View(x)
dat <- data.frame(Category = rep(factor(1:dimen),draws),
Density = as.vector(t(x)),
Draw = c(rep("Draw 1",dimen),
rep("Draw 2",dimen),
rep("Draw 3",dimen),
rep("Draw 4",dimen)))
View(dat)
View(x)
dat <- data.frame(Category = rep(factor(1:dimen),draws),
Density = as.vector(c(x[1,],x[2,],x[3,],x[4,]),
Draw = c(rep("Draw 1",dimen),
rep("Draw 2",dimen),
rep("Draw 3",dimen),
rep("Draw 4",dimen)))
dat <- data.frame(Category = rep(factor(1:dimen),draws),
Density = as.vector(c(x[1,],x[2,],x[3,],x[4,])),
Draw = c(rep("Draw 1",dimen),
rep("Draw 2",dimen),
rep("Draw 3",dimen),
rep("Draw 4",dimen)))
dat <- data.frame(Category = rep(factor(1:dimen),draws),
Density = as.vector(c(x[1,],x[2,],x[3,],x[4,])),
Draw = c(rep("Draw 1",dimen),
rep("Draw 2",dimen),
rep("Draw 3",dimen),
rep("Draw 4",dimen)))
?facet_wrap
library(ggplot2)
?facet_wrap
ggplot(dat,aes(x = Category,y = Density,ymin = 0, ymax = Density)) +
geom_point(colour = "darkblue",fill = "darkblue") +
geom_linerange(colour = "darkblue") +
scale_y_continuous(lim=c(0,0.5)) +
facet_wrap(~Draw, ncol = 2)
alpha <- 20
draws <- 4
dimen <- 20
alpha_m <- rep(alpha/dimen, dimen)
x <- rdirichlet_cpp(draws,alpha_m)
dat <- data.frame(Category = rep(factor(1:dimen),draws),
Density = as.vector(c(x[1,],x[2,],x[3,],x[4,])),
Draw = c(rep("Draw 1",dimen),
rep("Draw 2",dimen),
rep("Draw 3",dimen),
rep("Draw 4",dimen)))
ggplot(dat,aes(x = Category,y = Density,ymin = 0, ymax = Density)) +
geom_point(colour = "darkblue",fill = "darkblue") +
geom_linerange(colour = "darkblue") +
scale_y_continuous(lim=c(0,0.5)) +
facet_wrap(~Draw, ncol = 2)
data <- NULL
for (i in 1:471) {
print(i)
cur <- import(paste("dataset_",i,".csv", sep = ""))
data <- rbind(data,cur)
}
library(rio)
setwd("~/Documents/RA_and_Consulting_Work/ISSR_Data_Management_Web_Scraping_2017/Data/Multi_Datasets")
data <- NULL
for (i in 1:471) {
print(i)
cur <- import(paste("dataset_",i,".csv", sep = ""))
data <- rbind(data,cur)
}
files <- list.files()
470800 == nrow(data)
View(data)
sections <- data
Bill_ID <- rep("",nrow(sections))
# Loop over rows and fill in Bill_ID:
for (i in 1:nrow(sections)) {
Bill_ID[i] <- paste(sections$session[i],
sections$chamber[i],
sections$number[i],
sep = "-")
}
Bill_ID <- paste(sections$session,
sections$chamber,
sections$number,
sep = "-")
unique_bills <- unqieu(Bill_ID)
unique_bills <- unique(Bill_ID)
unique_bills <- unique(Bill_ID)
# create a vector to hold the count of sections in each unique bill:
Sections <- rep(0, length(unique_bills))
# Create a copy of sections in which we can delete rows:
bills <- sections
# Loop over unique bills:
for (i in 1:length(unique_bills)) {
# print out the current dataset to keep track of our progress:
if (i %% 1000 == 0) {
print(i)
}
# Find the rows associated with each unique bill:
inds <- which(Bill_ID == unique_bills[i])
# Record the number of sections associated with the current bill
Sections[i] <- length(inds)
# If there is more than one section, remove all but the first
if (length(inds) > 1) {
bills <- bills[-inds[-1],] # remove all rows except for the first one
# in inds
}
}
bills <- sections
bills <- bills[1:length(unique_bills),]
for (i in 1:length(unique_bills)) {
# print out the current dataset to keep track of our progress:
if (i %% 100 == 0) {
print(i)
}
# Find the rows associated with each unique bill:
inds <- which(Bill_ID == unique_bills[i])
# Record the number of sections associated with the current bill
Sections[i] <- length(inds)
# Replace the row with the correct data
bills[i,] <- sections[inds[1],]
}
for (i in 22950:length(unique_bills)) {
# print out the current dataset to keep track of our progress:
if (i %% 100 == 0) {
print(i)
}
# Find the rows associated with each unique bill:
inds <- which(Bill_ID == unique_bills[i])
# Record the number of sections associated with the current bill
Sections[i] <- length(inds)
# Replace the row with the correct data
bills[i,] <- sections[inds[1],]
}
View(bills)
bills <- bills[,-5] # remove the fifth column("section")
bills <- cbind(bills, Sections)
save(bills, file = "~/Desktop/Assignment_2_Bills.RData")
97428  == nrow(bills)
